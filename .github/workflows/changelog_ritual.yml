
# =============================================================
# ðŸ“œ Changelog Automation Ritual â€” Audit & Telemetry Sentinel
#
# This workflow generates, commits, and archives the changelog for every release.
#
# ðŸ”‘ Controls & Toggles:
#   - GITHUB_TOKEN:         GitHub Actions secret (for PR/release comments)
#   - GRAFANA_API_KEY:      GitHub secret (for changelog metrics)
#   - GRAFANA_INSTANCE:     Grafana instance URL (for metrics)
#   - CHANGELOG_SUMMARY_COMMENT: If 'false', disables PR/release summary comment (default: true)
#   - TRUNCATE_DIFF:        If 'true', truncates changelog diff in logs/comments
#
# ðŸ”„ Default Flow:
#   1. Generate and commit changelog
#   2. Show and comment changelog diff (truncated if toggle set)
#   3. Archive changelog artifact
#   4. Post changelog summary to PR/release (unless CHANGELOG_SUMMARY_COMMENT is false)
#   5. Push changelog metrics to Grafana (if secrets present)
#
# See /docs/changelog_ritual.md for full details.
# =============================================================
on:

name: Changelog Automation Ritual

on:
  push:
    tags:
      - 'v*.*.*'
  pull_request:            # temporary for dry-run PR validation
    types: [opened, synchronize, reopened]
  release:                 # optional, for posting diffs to release discussions
    types: [published]
  workflow_dispatch:

jobs:
  generate_changelog:
    name: Generate & Archive Changelog
    runs-on: ubuntu-latest
    env:
      CHANGELOG_PATH: CHANGELOG.md
      GITHUB_REPOSITORY: ${{ github.repository }}
      RELEASE_TAG: ${{ github.ref_name }}

    steps:
      - name: "ðŸ›¡ï¸ Validate Release Integrity"
        if: github.ref_type == 'tag'
        run: |
          echo "ðŸ” Validating release tag: $GITHUB_REF_NAME"
          [[ "$GITHUB_REF_NAME" =~ ^v[0-9]+\.[0-9]+\.[0-9]+$ ]] || {
            echo "âŒ Invalid semantic version format: $GITHUB_REF_NAME"
            echo "Expected format: v1.2.3"
            exit 1
          }

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install requests==2.32.5 PyGithub==2.7.0 python-dateutil==2.9.0.post0

      - name: Run changelog generation
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python .github/scripts/changelog_generate.py

      - name: Commit changelog
        id: commit_changelog
        run: |
          git config user.name "Strategist Bot"
          git config user.email "strategist@mesh.local"
          git add CHANGELOG.md
          if git diff --cached --quiet; then
            echo "No changes to commit."
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            git commit -m "chore: update changelog for $GITHUB_REF_NAME"
            git push || echo "No push on fork."
            echo "changed=true" >> $GITHUB_OUTPUT
          fi


      # ðŸ“ Show changelog diff in logs (truncated if TRUNCATE_DIFF is true)
      - name: Show changelog diff in logs
        if: steps.commit_changelog.outputs.changed == 'true'
        env:
          TRUNCATE_DIFF: ${{ env.TRUNCATE_DIFF || 'false' }}
        run: |
          if [ "$TRUNCATE_DIFF" = "true" ]; then
            echo "--- Truncated changelog diff (first 100 lines) ---"
            git show HEAD -- CHANGELOG.md | head -n 100
            echo "... Diff truncated â€” see artifact for full details."
          else
            echo "--- Changelog diff ---"
            git show HEAD -- CHANGELOG.md || echo "No changelog diff to show."
          fi


      # ðŸ—’ï¸ Post changelog summary to PR or release discussion
      # Includes lines changed, artifact link, and truncation/fallback if any.
      # Controlled by CHANGELOG_SUMMARY_COMMENT (default: true)
      - name: Post Changelog Summary Comment
        if: env.CHANGELOG_SUMMARY_COMMENT != 'false' && steps.commit_changelog.outputs.changed == 'true' && github.event_name != 'workflow_dispatch'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          DIFF_LINES=$(git show HEAD -- CHANGELOG.md | wc -l)
          ARTIFACT_URL="https://github.com/${{ github.repository }}/suites/${{ github.run_id }}/artifacts"
          SUMMARY="**Changelog Update**\n\nLines Changed: $DIFF_LINES\n[ðŸ”— Full Changelog Artifact]($ARTIFACT_URL)\nTimestamp: $(date -u +'%Y-%m-%dT%H:%M:%SZ')"
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            gh pr comment ${{ github.event.pull_request.number }} --body "$SUMMARY"
          elif [[ "${{ github.event_name }}" == "release" ]]; then
            gh release comment ${{ github.event.release.id }} --body "$SUMMARY"
          fi

      # ðŸ“Š Push changelog metrics to Grafana for operational telemetry
      # Mirrors Cloudflare sentinel's Grafana integration pattern.
      - name: Push Changelog Metrics to Grafana
        if: ${{ secrets.GRAFANA_API_KEY != '' && secrets.GRAFANA_INSTANCE != '' && steps.commit_changelog.outputs.changed == 'true' }}
        env:
          GRAFANA_API_KEY: ${{ secrets.GRAFANA_API_KEY }}
          GRAFANA_INSTANCE: ${{ secrets.GRAFANA_INSTANCE }}
        run: |
          DIFF_LINES=$(git show HEAD -- CHANGELOG.md | wc -l)
          curl -X POST "https://${GRAFANA_INSTANCE}/api/annotations" \
            -H "Authorization: Bearer ${GRAFANA_API_KEY}" \
            -H "Content-Type: application/json" \
            --data "{\n  \"tags\": [\"changelog\", \"update\"],\n  \"text\": \"Changelog update: lines=$DIFF_LINES\",\n  \"time\": $(date +%s%3N)\n}"
      - name: Archive changelog artifact
        uses: actions/upload-artifact@v4
        with:
          name: changelog
          path: CHANGELOG.md

      - name: Update PR body with changelog artifact link
        if: github.event_name == 'pull_request'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          ARTIFACT_URL="https://github.com/${{ github.repository }}/suites/${{ github.run_id }}/artifacts"
          BODY="$(gh pr view ${{ github.event.pull_request.number }} --json body -q '.body' | sed '/^\*\*ðŸ”— Full Changelog Artifact:/d')"
          gh pr edit ${{ github.event.pull_request.number }} \
            --body "$BODY\n\n**ðŸ”— Full Changelog Artifact:** [View here](${ARTIFACT_URL})"

      - name: Broadcast to Discord
        if: ${{ secrets.DISCORD_WEBHOOK_URL != '' }}
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          python .github/scripts/discord_broadcast.py

      - name: Push release metrics to Grafana
        if: ${{ secrets.GRAFANA_API_KEY != '' }}
        env:
          GRAFANA_API_KEY: ${{ secrets.GRAFANA_API_KEY }}
          GRAFANA_INSTANCE: alphafundbot.grafana.net
        run: |
          python .github/scripts/grafana_push.py

      - name: Lint workflow YAML
        uses: ibiqlik/action-yamllint@v3
        with:
          file_or_dir: .github/workflows/changelog_ritual.yml
      - name: Broadcast to Discord
        if: env.DISCORD_WEBHOOK_URL != ''
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
          RELEASE_TAG: ${{ github.ref_name }}
        run: python .github/scripts/discord_broadcast.py

jobs:

name: Changelog Automation Ritual
on:
  push:
    tags:
      - 'v*.*.*'
  workflow_dispatch:


  generate_changelog:
    name: Generate & Archive Changelog
    runs-on: ubuntu-latest
    steps:
      - name: "\U0001F6E1ï¸ Validate Release Integrity"
        run: |
          echo "\U0001F50D Validating release tag: $GITHUB_REF_NAME"
          [[ "$GITHUB_REF_NAME" =~ ^v[0-9]+\.[0-9]+\.[0-9]+$ ]] || {
            echo "âŒ Invalid semantic version format: $GITHUB_REF_NAME"
            echo "Expected format: v1.2.3"
            exit 1
          }
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          pip install requests==2.32.5 PyGithub==2.7.0 python-dateutil==2.9.0.post0

      - name: Run changelog generation
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          RELEASE_TAG: ${{ github.ref_name }}
          CHANGELOG_PATH: CHANGELOG.md
        run: |
          python .github/scripts/changelog_generate.py


      - name: Commit changelog
        id: commit_changelog
        run: |
          git config user.name "Strategist Bot"
          git config user.email "strategist@mesh.local"
          git add CHANGELOG.md
          if git diff --cached --quiet; then
            echo "No changes to commit."
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            git commit -m "chore: update changelog for $GITHUB_REF_NAME"
            git push || echo "No push on fork."
            echo "changed=true" >> $GITHUB_OUTPUT
          fi


      - name: Show changelog diff in logs
        if: steps.commit_changelog.outputs.changed == 'true'
        run: |
          echo "--- Changelog diff ---"
          git show HEAD -- CHANGELOG.md || echo "No changelog diff to show."

      # --- Dormant truncation guard: Uncomment to activate concise diffs ---
      # - name: Show truncated changelog diff in logs
      #   if: steps.commit_changelog.outputs.changed == 'true'
      #   run: |
      #     echo "--- Truncated changelog diff (first 100 lines) ---"
      #     git show HEAD -- CHANGELOG.md | head -n 100
      #     echo "... Diff truncated â€” see artifact for full details."


      - name: Comment changelog diff on PR or release
        if: steps.commit_changelog.outputs.changed == 'true' && github.event_name != 'workflow_dispatch'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Only post if this is a PR or release event
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            PR_NUMBER=${{ github.event.pull_request.number }}
            git show HEAD -- CHANGELOG.md > changelog.diff
            gh pr comment $PR_NUMBER --body "### :memo: Changelog Diff\n\n\`\`\`diff\n$(cat changelog.diff)\n\`\`\`"
          elif [[ "${{ github.event_name }}" == "release" ]]; then
            RELEASE_ID=${{ github.event.release.id }}
            git show HEAD -- CHANGELOG.md > changelog.diff
            gh release comment $RELEASE_ID --body "### :memo: Changelog Diff\n\n\`\`\`diff\n$(cat changelog.diff)\n\`\`\`"
          else
            echo "Not a PR or release event, skipping comment."
          fi

      # - name: Comment truncated changelog diff on PR or release
      #   if: steps.commit_changelog.outputs.changed == 'true' && github.event_name != 'workflow_dispatch'
      #   env:
      #     GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      #   run: |
      #     if [[ "${{ github.event_name }}" == "pull_request" ]]; then
      #       PR_NUMBER=${{ github.event.pull_request.number }}
      #       head -n 100 <(git show HEAD -- CHANGELOG.md) > changelog.diff
      #       echo "... Diff truncated â€” see artifact for full details." >> changelog.diff
      #       gh pr comment $PR_NUMBER --body "### :memo: Changelog Diff (truncated)\n\n\`\`\`diff\n$(cat changelog.diff)\n\`\`\`"
      #     elif [[ "${{ github.event_name }}" == "release" ]]; then
      #       RELEASE_ID=${{ github.event.release.id }}
      #       head -n 100 <(git show HEAD -- CHANGELOG.md) > changelog.diff
      #       echo "... Diff truncated â€” see artifact for full details." >> changelog.diff
      #       gh release comment $RELEASE_ID --body "### :memo: Changelog Diff (truncated)\n\n\`\`\`diff\n$(cat changelog.diff)\n\`\`\`"
      #     else
      #       echo "Not a PR or release event, skipping comment."

      - name: Archive changelog artifact
        uses: actions/upload-artifact@v4
        with:
          name: changelog
          path: CHANGELOG.md

      - name: Broadcast to Discord
        if: ${{ secrets.DISCORD_WEBHOOK_URL != '' }}
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
          RELEASE_TAG: ${{ github.ref_name }}
        run: |
          python .github/scripts/discord_broadcast.py

      - name: Push release metrics to Grafana
        if: ${{ secrets.GRAFANA_API_KEY != '' }}
        env:
          GRAFANA_API_KEY: ${{ secrets.GRAFANA_API_KEY }}
          GRAFANA_INSTANCE: alphafundbot.grafana.net
          RELEASE_TAG: ${{ github.ref_name }}
        run: |
          python .github/scripts/grafana_push.py

      # --- Lattice Trend Digest: Unified Metrics-to-Briefing Ritual ---
      - name: Generate Lattice Trend Digest
      if: ${{ secrets.GRAFANA_API_KEY != '' && secrets.GRAFANA_INSTANCE != '' }}
      env:
        GRAFANA_API_KEY: ${{ secrets.GRAFANA_API_KEY }}
        GRAFANA_INSTANCE: ${{ secrets.GRAFANA_INSTANCE }}
        ENABLE_SNAPSHOTS: ${{ env.ENABLE_SNAPSHOTS || 'false' }}
        GRAFANA_SNAPSHOT_URLS: ${{ env.GRAFANA_SNAPSHOT_URLS || '' }}
      run: |
        import os
        import requests
        from datetime import datetime, timedelta

        # =========================
        # ðŸ“œ Lattice Trend Digest: Unified Metrics-to-Briefing Block
        # - Authenticates to Grafana API
        # - Queries for purges, changelog lines, anomalies (current & previous week)
        # - Calculates deltas, applies severity, embeds snapshots if enabled
        # - Writes digest.md for posting, archiving, and broadcast
        # =========================

        # ---- Configurable thresholds & toggles ----
        SEVERITY_CONFIG = {
          "purges": {"warning": 10, "critical": 25},
          "changelog_lines": {"warning": 15, "critical": 40},
          "anomalies": {"warning": 1, "critical": 3}
        }
        ENABLE_SNAPSHOTS = os.getenv("ENABLE_SNAPSHOTS", "false").lower() == "true"
        SNAPSHOT_URLS = [u for u in os.getenv("GRAFANA_SNAPSHOT_URLS", "").split(",") if u.strip()] if ENABLE_SNAPSHOTS else []

        # ---- Grafana API setup ----
        GRAFANA_API_KEY = os.environ["GRAFANA_API_KEY"]
        GRAFANA_INSTANCE = os.environ["GRAFANA_INSTANCE"]
        HEADERS = {"Authorization": f"Bearer {GRAFANA_API_KEY}", "Content-Type": "application/json"}
        BASE_URL = f"https://{GRAFANA_INSTANCE}/api/ds/query"

        # ---- Metric queries (replace with your actual datasource/metric info) ----
        DATASOURCE_UID = "your-datasource-uid"  # <-- Replace with your actual datasource UID
        METRICS = {
          "purges": "sum(purges)",
          "changelog_lines": "sum(changelog_lines)",
          "anomalies": "sum(anomalies)"
        }

        def query_metric(expr, start, end):
          # Query Grafana for a metric over a time range (Prometheus-style example)
          payload = {
            "queries": [
              {
                "refId": "A",
                "datasource": {"uid": DATASOURCE_UID},
                "expr": expr,
                "intervalMs": 60000,
                "maxDataPoints": 1
              }
            ],
            "range": {
              "from": start.isoformat() + "Z",
              "to": end.isoformat() + "Z"
            }
          }
          resp = requests.post(BASE_URL, headers=HEADERS, json=payload)
          if not resp.ok:
            raise RuntimeError(f"Grafana query failed: {resp.status_code} {resp.text}")
          data = resp.json()
          try:
            # Prometheus-style: data["results"]["A"]["frames"][0]["data"]["values"][1][0]
            val = float(data["results"]["A"]["frames"][0]["data"]["values"][1][0])
          except Exception:
            raise RuntimeError(f"No data for query: {expr}")
          return val

        # ---- Time windows ----
        now = datetime.utcnow()
        week_ago = now - timedelta(days=7)
        two_weeks_ago = now - timedelta(days=14)

        # ---- Fetch metrics ----
        current_metrics = {}
        previous_metrics = {}
        for metric, expr in METRICS.items():
          # Current week: [week_ago, now)
          current_metrics[metric] = query_metric(expr, week_ago, now)
          # Previous week: [two_weeks_ago, week_ago)
          previous_metrics[metric] = query_metric(expr, two_weeks_ago, week_ago)

        # ---- Delta/severity logic ----
        def calc_delta(metric_name):
          curr = current_metrics.get(metric_name, 0)
          prev = previous_metrics.get(metric_name, 0)
          delta_pct = ((curr - prev) / prev * 100) if prev else 0
          sev_cfg = SEVERITY_CONFIG.get(metric_name, {})
          marker = ""
          if abs(delta_pct) >= sev_cfg.get("critical", 999):
            marker = "ðŸš¨"
          elif abs(delta_pct) >= sev_cfg.get("warning", 999):
            marker = "ðŸŸ¡"
          return curr, delta_pct, marker

        # ---- Build digest ----
        digest_lines = []
        digest_lines.append(f"# State of the Lattice â€” {now.strftime('%Y-%m-%d')}")
        digest_lines.append("")
        digest_lines.append("## Cloudflare Purges")
        purges, purges_delta, purges_marker = calc_delta("purges")
        digest_lines.append(f"- Total Purges: **{purges:.0f}** ({purges_delta:+.1f}%){purges_marker}")

        digest_lines.append("")
        digest_lines.append("## Changelog Activity")
        lines, lines_delta, lines_marker = calc_delta("changelog_lines")
        digest_lines.append(f"- Lines Changed: **{lines:.0f}** ({lines_delta:+.1f}%){lines_marker}")

        digest_lines.append("")
        digest_lines.append("## Anomalies")
        anomalies, anomalies_delta, anomalies_marker = calc_delta("anomalies")
        digest_lines.append(f"- Count: **{anomalies:.0f}** ({anomalies_delta:+.1f}%){anomalies_marker}")

        # ---- Optional Grafana snapshots ----
        if ENABLE_SNAPSHOTS and SNAPSHOT_URLS:
          digest_lines.append("")
          digest_lines.append("## Visuals")
          for url in SNAPSHOT_URLS:
            digest_lines.append(f"![Grafana Panel]({url.strip()})")

        # ---- Write digest to file for comment/artifact steps ----
        with open("digest.md", "w", encoding="utf-8") as f:
          f.write("\n".join(digest_lines))

        print("Digest generated:\n", "\n".join(digest_lines))
